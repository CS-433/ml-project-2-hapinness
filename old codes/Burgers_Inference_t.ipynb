{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96699085",
   "metadata": {},
   "source": [
    "### Burgers Equation \n",
    "General form:\n",
    "$$\\frac{\\partial u(t,x)}{\\partial t} + \\lambda _{1} u(t,x) \\frac{\\partial u(t,x)}{\\partial x} -\\lambda _{2} \\frac{\\partial^2 u(t,x)}{\\partial x^2} = 0$$\n",
    "We will work on the following form: $$\\frac{\\partial u(t,x)}{\\partial t} + u(t,x) \\frac{\\partial u(t,x)}{\\partial x} -\\frac{0.01}{\\pi} \\frac{\\partial^2 u(t,x)}{\\partial x^2} = 0$$\n",
    "With the following boundary and initial conditions:\n",
    "$$u(0,x) = -sin(\\pi x) \\textrm{, which is the initial condition}$$ <br>\n",
    "$$u(t,-1) = u(t,1) = 0 \\textrm{, which is the Dirichlet boundary conditions}$$<br>\n",
    "$$x \\in [-1,1], \\textrm{ }t\\in [0,1]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767b6fc5",
   "metadata": {},
   "source": [
    "### Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43364ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "from pyDOE import lhs\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "lambda_1 = 1\n",
    "lambda_2 = 0.01/np.pi     \n",
    "\n",
    "N_u = 100\n",
    "N_f = 5000\n",
    "\n",
    "data = scipy.io.loadmat('burgers_shock.mat')\n",
    "\n",
    "t_sol = data['t'].flatten()[:,None] #100,1\n",
    "x_sol = data['x'].flatten()[:,None] #256,1\n",
    "U_sol = np.real(data['usol']) #256,100\n",
    "\n",
    "T, X = np.meshgrid(t_sol,x_sol) #X 256,100; T 256,100\n",
    "\n",
    "t_x_sol = np.hstack(( T.flatten()[:,None],X.flatten()[:,None])) #25600, 2, exact solution input pairs (t,x)\n",
    "u_sol = U_sol.flatten()[:,None] #25600, 1, exact solution u(t,x)  \n",
    "\n",
    "ic = np.hstack((T[:,0:1], X[:,0:1])) #256, 2; corresponds to the initial condition points u(t=0,x) = -sin(pix)\n",
    "#ic_sol = Exact[:,0:1]\n",
    "ic_sol = -np.sin(ic[:,1]*np.pi).reshape(-1,1)\n",
    "\n",
    "bc1 = np.hstack((T[0:1,:].T, X[0:1,:].T)) #100, 2; correspond to the first boundary condition u(t,x=-1) = 0\n",
    "#bc1_sol = Exact[0:1,:].T #100, 1; exact solution for the first boundary condition\n",
    "bc1_sol = np.zeros(bc1[:,0:1].shape)\n",
    "\n",
    "bc2 = np.hstack((T[-1:,:].T, X[-1:,:].T)) #100, 2; corresponds to the second boundary condition u(t,x=1) = 0\n",
    "#bc2_sol = Exact[-1:,:].T #100, 1; exact solution for the second boundary condition\n",
    "bc2_sol = np.zeros(bc2[:,0:1].shape)\n",
    "\n",
    "t_x_train = np.vstack([ic, bc1, bc2]) #456, 2 #points of initial and boundaries conditions points\n",
    "t_x_train_reserve = t_x_train.copy()\n",
    "u_train = np.vstack([ic_sol, bc1_sol, bc2_sol]) # 456, 1; stack the exact solution points for initial and boundaries conditions\n",
    "u_train_reserve = u_train.copy()\n",
    "lower_bound_domain = t_x_sol.min(0)\n",
    "upper_bound_domain = t_x_sol.max(0)\n",
    "\n",
    "def generate_training_data(Nu, Nf, tx_tr, u_tr, lb, ub):\n",
    "    #Latin hypercube sampling: creates 10000 near random pairs of (x,t) in the domain [-1,1]x[0,0.99], used for PDE\n",
    "    tx_f = lb + (ub-lb)*lhs(2, Nf) #10000, 2 \n",
    "    #stack initial and boundaries points with PDE points, so all the the initial and boundaries points can also be used for the PDE \n",
    "    tx_f = np.vstack((tx_f, tx_tr)) #10456, 2 \n",
    "    \n",
    "    #(100,) 100 permutations from the 456 initial and boundaries conditions, N_u = 100\n",
    "    idx = np.random.choice(tx_tr.shape[0], Nu, replace=False) \n",
    "    tx_tr = tx_tr[idx, :] #100,2 randomly points from the 456 initial and boundaries conditions\n",
    "    u_tr = u_tr[idx,:] #100,1 randomly points from the 456 exact solutions points of initial and boundaries conditions\n",
    "    \n",
    "    return tx_f, tx_tr, u_tr\n",
    "\n",
    "t_x_f, t_x_train, u_train = generate_training_data(N_u, N_f, t_x_train, u_train, lower_bound_domain, upper_bound_domain)\n",
    "\n",
    "print(f\"Training data size: {t_x_train.shape}\")\n",
    "print(f\"Collocation points size: {t_x_f.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e7a501",
   "metadata": {},
   "source": [
    "### DNN definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bcfdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)\n",
    "from collections import OrderedDict \n",
    "class DNN(torch.nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(DNN, self).__init__()\n",
    "        \n",
    "        self.activation = torch.nn.Tanh\n",
    "        \n",
    "        layer_list = list()\n",
    "        for i in range(len(layers) - 2): \n",
    "            layer_list.append(\n",
    "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
    "            )\n",
    "            layer_list.append(('activation_%d' % i, self.activation()))\n",
    "            \n",
    "        layer_list.append(\n",
    "            ('layer_%d' % (len(layers) - 2), torch.nn.Linear(layers[-2], layers[-1]))\n",
    "        )\n",
    "        layerDict = OrderedDict(layer_list)\n",
    "\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d82366c",
   "metadata": {},
   "source": [
    "### PINN definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337d97ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "class PINN():\n",
    "    def __init__(self, layers, tx_tr, u_tr, tx_f, lambda_1, lambda_2, max_iter=1, learning_rate=1.0, hs=50, tol = 1e-5, verbose=True):\n",
    "        \n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"device used: {self.device}\")\n",
    "        \n",
    "        \n",
    "        self.t_tr = torch.tensor(tx_tr[:, 0:1], requires_grad=True).float().to(self.device) \n",
    "        self.x_tr = torch.tensor(tx_tr[:, 1:2], requires_grad=True).float().to(self.device) \n",
    "        self.t_f = torch.tensor(tx_f[:, 0:1], requires_grad=True).float().to(self.device)\n",
    "        self.x_f = torch.tensor(tx_f[:, 1:2], requires_grad=True).float().to(self.device) \n",
    "        self.u_tr = torch.tensor(u_tr).float().to(self.device)\n",
    "        self.zeros = torch.torch.zeros(self.x_f.shape).float().to(self.device)\n",
    "        self.lambda_1 = lambda_1\n",
    "        self.lambda_2 = lambda_2\n",
    "        self.verbose = verbose\n",
    " \n",
    "        self.net = DNN(layers).to(self.device)\n",
    "    \n",
    "        self.iter = 1\n",
    "       \n",
    "        self.max_iter = max_iter\n",
    "        \n",
    "        #self.criterion = torch.nn.MSELoss()\n",
    "        \n",
    "        self.optimizer = torch.optim.LBFGS(\n",
    "            self.net.parameters(), \n",
    "            lr=learning_rate, \n",
    "            max_iter=50000, \n",
    "            max_eval=50000, \n",
    "            history_size= hs,\n",
    "            tolerance_grad=tol, \n",
    "            tolerance_change=1.0 * np.finfo(float).eps,\n",
    "            line_search_fn=\"strong_wolfe\"    \n",
    "        )\n",
    "            \n",
    "    def net_u(self, t, x): #get u(t,x) for a pair (x,t); a forward pass through the PINN\n",
    "        u = self.net(torch.cat([t, x], dim=1))\n",
    "        return u #u(t,x)\n",
    "    \n",
    "    def net_f(self, t, x, get_all = False): #get f = u_t + u * u_x - self.nu * u_xx; the true u(x,t) makes f = 0\n",
    "        u = self.net_u(t, x)\n",
    "        u_t = torch.autograd.grad( #first partial derivative with respect to t\n",
    "            u, t, \n",
    "            grad_outputs=torch.ones_like(u),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        u_x = torch.autograd.grad( #first partial derivative with respect to x\n",
    "            u, x, \n",
    "            grad_outputs=torch.ones_like(u),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        u_xx = torch.autograd.grad( #second partial derivative with respect to x\n",
    "            u_x, x, \n",
    "            grad_outputs=torch.ones_like(u_x),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        f = u_t + self.lambda_1 * u * u_x - self.lambda_2 * u_xx #the computed PDE, we want to be a close as possible to 0\n",
    "        if get_all:\n",
    "            return f, u, u_t, u_x, u_xx\n",
    "        else:\n",
    "            return f\n",
    "        \n",
    "    def pinn_loss(self):\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        u_pred = self.net_u(self.t_tr, self.x_tr) #100, 1; all the ic/bc pairs were feeded through the PINN\n",
    "        #loss_u = self.criterion(u_pred, self.u_tr)\n",
    "        loss_u = torch.mean((self.u_tr - u_pred) ** 2) #MSE loss on the ic/bc pairs, MSE loss on trainset, classic NN\n",
    "        \n",
    "        f_pred = self.net_f(self.t_f, self.x_f) #10456, 1; all the collocations points were feeded through the PINN\n",
    "        #loss_f = self.criterion(f_pred, self.zeros)\n",
    "        loss_f = torch.mean(f_pred ** 2) #MSE loss on the collocations pairs, regularization term\n",
    "        \n",
    "        loss = loss_u + loss_f #classic loss + regularization loss (enforce the PDE structure) => PINN loss\n",
    "        \n",
    "        loss.backward() #backpropagation\n",
    "        \n",
    "        self.iter += 1\n",
    "        if self.verbose:\n",
    "            if self.iter % 100 == 0:\n",
    "                print(\n",
    "                    'Iter %d, Loss: %.5e, Loss_u: %.5e, Loss_f: %.5e' % (self.iter, loss.item(), loss_u.item(), loss_f.item())\n",
    "                )\n",
    "        return loss\n",
    "    \n",
    "    def train(self):\n",
    "        for i in range(self.max_iter):\n",
    "            self.net.train()\n",
    "            self.optimizer.step(self.pinn_loss)\n",
    "\n",
    "            \n",
    "    def predict(self, t_x):\n",
    "        t = torch.tensor(t_x[:, 0:1], requires_grad=True).float().to(self.device) #get x from pair\n",
    "        x = torch.tensor(t_x[:, 1:2], requires_grad=True).float().to(self.device) #get t from pair\n",
    "        self.net.eval()\n",
    "        f, u, ut, ux, uxx = self.net_f(t, x, True)\n",
    "        u = self.net_u(t, x) \n",
    "        f = self.net_f(t, x) \n",
    "        u = u.detach().cpu().numpy()\n",
    "        f = f.detach().cpu().numpy()\n",
    "        return u, ut, ux, uxx, f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018fbb46",
   "metadata": {},
   "source": [
    "### Network Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12ac9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_per_layer = 20\n",
    "hidden_layers = 9\n",
    "layers = np.hstack([np.array([2]),np.full(hidden_layers, nodes_per_layer),np.array([1])])\n",
    "\n",
    "\"\"\"net = DNN(layers)\n",
    "print(net)\n",
    "\n",
    "params = list(net.parameters())\n",
    "#print(len(params))\n",
    "for par in params:\n",
    "    print(par.shape)\"\"\"\n",
    "\n",
    "max_iter = 1\n",
    "lr = 1.0\n",
    "history_size = 50\n",
    "tol = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2c13cc",
   "metadata": {},
   "source": [
    "### Create and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960eb83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PINN(layers, t_x_train, u_train, t_x_f, lambda_1, lambda_2, max_iter=max_iter, learning_rate=lr, hs=history_size, tol = tol)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f1670c",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0887988f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_2_norm (pred, true):\n",
    "    return np.linalg.norm(pred-true,2)/np.linalg.norm(true,2)\n",
    "def MSE (pred, true):\n",
    "    return float(((pred - true)**2).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f556c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_pred, _, _, _, f_pred = model.predict(t_x_sol)\n",
    "\n",
    "L2_error_u = L_2_norm(u_pred, u_sol)\n",
    "\n",
    "MSE_error_u = MSE(u_pred, u_sol)\n",
    "MSE_error_f = MSE(f_pred, np.zeros(f_pred.shape))\n",
    "\n",
    "print(f\"L2 norm error u(t,x): {L2_error_u}\")\n",
    "print(f\"MSE error u(t,x): {MSE_error_u}\")\n",
    "print(f\"MSE error PDE: {MSE_error_f}\")\n",
    "\n",
    "from scipy.interpolate import griddata\n",
    "U_pred = griddata(t_x_sol, u_pred.flatten(), (T, X), method='cubic')\n",
    "#Error = np.abs(Exact - U_pred) #100, 256 matrix of errors compared to burgers_shock.mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f03a8e",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5a8e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "fig = plt.figure(figsize=(9, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "h = ax.imshow(U_pred.T, interpolation='nearest', cmap='rainbow', \n",
    "              extent=[t_sol.min(), t_sol.max(), x_sol.min(), x_sol.max()], \n",
    "              origin='lower', aspect='auto')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.10)\n",
    "cbar = fig.colorbar(h, cax=cax)\n",
    "cbar.ax.tick_params(labelsize=15) \n",
    "\n",
    "ax.plot(\n",
    "    t_x_train[:,0], \n",
    "    t_x_train[:,1], \n",
    "    'kx', label = 'Data (%d points)' % (u_train.shape[0]), \n",
    "    markersize = 4,  # marker size doubled\n",
    "    clip_on = False,\n",
    "    alpha=1.0\n",
    ")\n",
    "\n",
    "line = np.linspace(x_sol.min(), x_sol.max(), 2)[:,None]\n",
    "ax.plot(t_sol[25]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
    "ax.plot(t_sol[50]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
    "ax.plot(t_sol[75]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
    "\n",
    "ax.set_xlabel('$t$', size=20)\n",
    "ax.set_ylabel('$x$', size=20)\n",
    "ax.legend(\n",
    "    loc='upper center', \n",
    "    bbox_to_anchor=(0.9, -0.05), \n",
    "    ncol=5, \n",
    "    frameon=False, \n",
    "    prop={'size': 15}\n",
    ")\n",
    "ax.set_title('$u(t,x)$', fontsize = 20) # font size doubled\n",
    "ax.tick_params(labelsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9876a475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "fig = plt.figure(figsize=(14, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "gs1 = gridspec.GridSpec(1, 3)\n",
    "gs1.update(top=1-1.0/3.0-0.1, bottom=1.0-2.0/3.0, left=0.1, right=0.9, wspace=0.5)\n",
    "\n",
    "ax = plt.subplot(gs1[0, 0])\n",
    "ax.plot(x_sol,U_sol[:,25], 'b-', linewidth = 2, label = 'Exact')       \n",
    "ax.plot(x_sol,U_pred[:,25], 'r--', linewidth = 2, label = 'Prediction')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$u(t,x)$')    \n",
    "ax.set_title('$t = 0.25$', fontsize = 15)\n",
    "ax.axis('square')\n",
    "ax.set_xlim([-1.1,1.1])\n",
    "ax.set_ylim([-1.1,1.1])\n",
    "\n",
    "for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "             ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    item.set_fontsize(15)\n",
    "\n",
    "ax = plt.subplot(gs1[0, 1])\n",
    "ax.plot(x_sol,U_sol[:,50], 'b-', linewidth = 2, label = 'Exact')       \n",
    "ax.plot(x_sol,U_pred[:,50], 'r--', linewidth = 2, label = 'Prediction')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$u(t,x)$')\n",
    "ax.axis('square')\n",
    "ax.set_xlim([-1.1,1.1])\n",
    "ax.set_ylim([-1.1,1.1])\n",
    "ax.set_title('$t = 0.50$', fontsize = 15)\n",
    "ax.legend(\n",
    "    loc='upper center', \n",
    "    bbox_to_anchor=(0.5, -0.15), \n",
    "    ncol=5, \n",
    "    frameon=False, \n",
    "    prop={'size': 15}\n",
    ")\n",
    "\n",
    "for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "             ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    item.set_fontsize(15)\n",
    "\n",
    "ax = plt.subplot(gs1[0, 2])\n",
    "ax.plot(x_sol,U_sol[:,75], 'b-', linewidth = 2, label = 'Exact')       \n",
    "ax.plot(x_sol,U_pred[:,75], 'r--', linewidth = 2, label = 'Prediction')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$u(t,x)$')\n",
    "ax.axis('square')\n",
    "ax.set_xlim([-1.1,1.1])\n",
    "ax.set_ylim([-1.1,1.1])    \n",
    "ax.set_title('$t = 0.75$', fontsize = 15)\n",
    "\n",
    "for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "             ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    item.set_fontsize(15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d7a0f6",
   "metadata": {},
   "source": [
    "### Network architecture comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb07b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_neurons = [10, 20, 40]\n",
    "nb_hidden_layers = [2, 4, 6, 8, 10]\n",
    "\n",
    "L2_u_1 = list\n",
    "MSE_u_1 = list()\n",
    "MSE_f_1 = list()\n",
    "\n",
    "for i in range(len(nb_hidden_layers)):\n",
    "    for j in range(len(nb_neurons)):\n",
    "        layers = np.hstack([np.array([2]),np.full(nb_hidden_layers[i], nb_neurons[j]),np.array([1])])\n",
    "        #verbose = False\n",
    "        model = PINN(layers, t_x_train, u_train, t_x_f, lambda_1, lambda_2, max_iter=max_iter, learning_rate=lr, hs=history_size, tol = tol, verbose = False)\n",
    "        model.train()\n",
    "        u_pred, _, _, _, f_pred = model.predict(t_x_sol)\n",
    "        L2_u_1.append(L_2_norm(u_pred, u_sol))\n",
    "        MSE_u_1.append(MSE(u_pred, u_sol))\n",
    "        MSE_f_1.append(MSE(f_pred, np.zeros(f_pred.shape)))\n",
    "        \n",
    "\n",
    "Nu = [10, 50 , 100, 200]\n",
    "Nf = [1000, 2000, 5000, 1000]\n",
    "\n",
    "L2_u_2 = list\n",
    "MSE_u_2 = list()\n",
    "MSE_f_2 = list()\n",
    "nodes_per_layer = 20\n",
    "hidden_layers = 9\n",
    "layers = np.hstack([np.array([2]),np.full(hidden_layers, nodes_per_layer),np.array([1])])\n",
    "\n",
    "for i in range(len(Nu)):\n",
    "    for j in range(len(Nf)):\n",
    "        t_x_f, t_x_train, u_train = generate_training_data(Nu[i], Nf[f], tx_train_reserve, u_train_reserve, lower_bound_domain, upper_bound_domain)\n",
    "        #verbose = False\n",
    "        model = PINN(layers, t_x_train, u_train, t_x_f, lambda_1, lambda_2, max_iter=max_iter, learning_rate=lr, hs=history_size, tol = tol, verbose = False)\n",
    "        model.train()\n",
    "        u_pred, _, _, _, f_pred = model.predict(t_x_sol)\n",
    "        L2_u_2.append(L_2_norm(u_pred, u_sol))\n",
    "        MSE_u_2.append(MSE(u_pred, u_sol))\n",
    "        MSE_f_2.append(MSE(f_pred, np.zeros(f_pred.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8202fd92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
