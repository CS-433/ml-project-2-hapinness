{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/jayroxis/PINNs/blob/master/Burgers%20Equation/Burgers.ipynb\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import scipy.io\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "plt.rcParams.update({                      # setup matplotlib to use latex for output\n",
    "    \"pgf.texsystem\": \"pdflatex\",        # change this if using xetex or lautex\n",
    "    \"text.usetex\": True,                # use LaTeX to write all text\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [],                   # blank entries should cause plots to inherit fonts from the document\n",
    "    \"font.sans-serif\": [],\n",
    "    \"font.monospace\": [],\n",
    "    \"figure.figsize\": (12,8),\n",
    "    \"axes.labelsize\": 12,               # LaTeX default is 10pt font.\n",
    "    \"font.size\": 11,\n",
    "    \"legend.fontsize\": 10,               # Make the legend/label fonts a little smaller\n",
    "    \"xtick.labelsize\": 10,\n",
    "    \"ytick.labelsize\": 10,\n",
    "    \"pgf.preamble\": [\n",
    "        r\"\\usepackage[utf8x]{inputenc}\",    # use utf8 fonts becasue your computer can handle it :)\n",
    "        r\"\\usepackage[T1]{fontenc}\",        # plots will be generated using this preamble\n",
    "        ]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-layer Perceptron\n",
    "class NN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        hidden_size,\n",
    "        output_size,\n",
    "        depth,\n",
    "        act=torch.nn.Tanh,\n",
    "    ):\n",
    "        super(NN, self).__init__()\n",
    "        \n",
    "        layers = [('input', torch.nn.Linear(input_size, hidden_size))]\n",
    "        layers.append(('input_activation', act()))\n",
    "        for i in range(depth): \n",
    "            layers.append(\n",
    "                ('hidden_%d' % i, torch.nn.Linear(hidden_size, hidden_size))\n",
    "            )\n",
    "            layers.append(('activation_%d' % i, act()))\n",
    "        layers.append(('output', torch.nn.Linear(hidden_size, output_size)))\n",
    "\n",
    "        layerDict = OrderedDict(layers)\n",
    "        self.layers = torch.nn.Sequential(layerDict)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net:\n",
    "    def __init__(self):\n",
    "        device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "        self.model = NN(\n",
    "            input_size=2,\n",
    "            hidden_size=20,\n",
    "            output_size=1,\n",
    "            depth=4,\n",
    "            act=torch.nn.Tanh\n",
    "        ).to(device)\n",
    "        \n",
    "        self.h = 0.1\n",
    "        self.k = 0.1\n",
    "        x = torch.arange(-1, 1 + self.h, self.h)\n",
    "        t = torch.arange(0, 1 + self.k, self.k)\n",
    "\n",
    "        # exact solution\n",
    "        self.X = torch.stack(torch.meshgrid(x, t)).reshape(2, -1).T\n",
    "        \n",
    "        # training data\n",
    "        bc1 = torch.stack(torch.meshgrid(x[0], t)).reshape(2, -1).T\n",
    "        bc2 = torch.stack(torch.meshgrid(x[-1], t)).reshape(2, -1).T\n",
    "        ic = torch.stack(torch.meshgrid(x, t[0])).reshape(2, -1).T\n",
    "        self.X_train = torch.cat([bc1, bc2, ic])\n",
    "        y_bc1 = torch.zeros(len(bc1))\n",
    "        y_bc2 = torch.zeros(len(bc2))\n",
    "        y_ic = -torch.sin(math.pi * ic[:, 0])\n",
    "        self.y_train = torch.cat([y_bc1, y_bc2, y_ic])\n",
    "        self.y_train = self.y_train.unsqueeze(1)\n",
    "        \n",
    "        self.X = self.X.to(device)\n",
    "        self.X_train = self.X_train.to(device)\n",
    "        self.y_train = self.y_train.to(device)\n",
    "        self.X.requires_grad = True\n",
    "        \n",
    "        self.criterion = torch.nn.MSELoss()\n",
    "        self.iter = 1\n",
    "        \n",
    "        self.optimizer = torch.optim.LBFGS(\n",
    "            self.model.parameters(), \n",
    "            lr=1.0, \n",
    "            max_iter=50000, \n",
    "            max_eval=50000, \n",
    "            history_size=50,\n",
    "            tolerance_grad=1e-5, \n",
    "            tolerance_change=1.0 * np.finfo(float).eps\n",
    "        )\n",
    "        \n",
    "        self.adam = torch.optim.Adam(self.model.parameters())\n",
    "        \n",
    "    def loss_func(self):\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = self.model(self.X_train)\n",
    "        loss_data = self.criterion(y_pred, self.y_train)\n",
    "\n",
    "        u = self.model(self.X)\n",
    "\n",
    "        du_dX = torch.autograd.grad(inputs=self.X, outputs=u, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
    "        du_dt = du_dX[:, 1]\n",
    "        du_dx = du_dX[:, 0]\n",
    "        du_dxx = torch.autograd.grad(inputs=self.X, outputs=du_dX, grad_outputs=torch.ones_like(du_dX), retain_graph=True, create_graph=True)[0][:, 0]\n",
    "#         print(u.shape, du_dt.shape, du_dx.shape, du_dxx.shape)\n",
    "        loss_pde = self.criterion(du_dt + u.squeeze() * du_dx, 0.01 / math.pi * du_dxx)\n",
    "\n",
    "        loss = loss_pde + loss_data\n",
    "        loss.backward()\n",
    "        if self.iter % 100 == 0: \n",
    "            print(self.iter, loss.item())\n",
    "        self.iter = self.iter + 1\n",
    "        return loss\n",
    "    \n",
    "    def train(self):\n",
    "        for i in range(1000):\n",
    "            self.adam.step(self.loss_func)\n",
    "        self.optimizer.step(self.loss_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jayroxis/.local/lib/python3.6/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.18140295147895813\n",
      "200 0.09370769560337067\n",
      "300 0.07628022134304047\n",
      "400 0.06667067855596542\n",
      "500 0.049526359885931015\n",
      "600 0.03457105904817581\n",
      "700 0.027608241885900497\n",
      "800 0.020747315138578415\n",
      "900 0.019751906394958496\n",
      "1000 0.0156443789601326\n",
      "1100 0.16815395653247833\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 0.01\n",
    "k = 0.01\n",
    "x = torch.arange(-1, 1, h)\n",
    "t = torch.arange(0, 1, k)\n",
    "\n",
    "# exact solution\n",
    "X = torch.stack(torch.meshgrid(x, t)).reshape(2, -1).T\n",
    "X = X.to(net.X.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net.model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X).reshape(len(x), len(t)).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(y_pred, cmap='jet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = {'v': y_pred}\n",
    "scipy.io.savemat('burgers_pinn.mat', mat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
