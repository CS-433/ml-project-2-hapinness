{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4940a31e",
   "metadata": {},
   "source": [
    "### References\n",
    "##### Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations \n",
    "\n",
    "https://www.sciencedirect.com/science/article/pii/S0021999118307125\n",
    "\n",
    "##### Physics Informed Deep Learning (Part I): Data-driven Solutions of Nonlinear Partial Differential Equations\n",
    "\n",
    "https://arxiv.org/pdf/1711.10561.pdf\n",
    "\n",
    "##### Physics Informed Deep Learning (Part II): Data-driven Discovery of Nonlinear Partial Differential Equations\n",
    "\n",
    "https://arxiv.org/pdf/1711.10566.pdf\n",
    "\n",
    "##### Authors: Maziar Raissi, Paris Perdikaris, George Em Karniadakis\n",
    "\n",
    "https://github.com/maziarraissi/PINNs <br>\n",
    "https://maziarraissi.github.io/PINNs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e2230a",
   "metadata": {},
   "source": [
    "### 1)Burgers' equation\n",
    "Physics form:\n",
    "$$\\frac{\\partial u(t,x)}{\\partial t} + u(t,x) \\frac{\\partial u(t,x)}{\\partial x} = \\nu \\frac{\\partial^2 u(t,x)}{\\partial x^2}$$\n",
    "$u(t,x)$: velocity of fluid, $\\nu$: viscosity of fluid <br><br>\n",
    "\n",
    "General form:\n",
    "$$\\frac{\\partial u(t,x)}{\\partial t} + \\lambda _{1} u(t,x) \\frac{\\partial u(t,x)}{\\partial x} -\\lambda _{2} \\frac{\\partial^2 u(t,x)}{\\partial x^2} = 0$$<br>\n",
    "\n",
    "In Maziar Raissi, Paris Perdikaris, and George Em Karniadakis paper: <br>\n",
    "$$\\frac{\\partial u(t,x)}{\\partial t} + u(t,x) \\frac{\\partial u(t,x)}{\\partial x} -\\frac{0.01}{\\pi} \\frac{\\partial^2 u(t,x)}{\\partial x^2} = 0$$ <br>\n",
    "$$u(0,x) = -sin(\\pi x) \\textrm{, which is the initial condition}$$ <br>\n",
    "$$u(t,-1) = u(t,1) = 0 \\textrm{, which is the Dirichlet boundary conditions}$$<br>\n",
    "$$x \\in [-1,1], \\textrm{ }t\\in [0,1]$$\n",
    "Close to the exact solution is $u(t,x) = e^{-t}sin(\\pi x)$, [here is the exact analytical solution.](https://www.sciencedirect.com/science/article/abs/pii/0045793086900368)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706b218c",
   "metadata": {},
   "source": [
    "### 2)PINN approach: Inference => find u(t,x) (Appendix A1 Data-driven solution of partial differential equations)\n",
    "In this part, we are looking to find the exact solution of the PDE (partial derivate equation), $u(t,x)$.\n",
    "\n",
    "Define $f := u_t + uu_x - \\frac{0.01}{\\pi}u_{xx}$, this function is an approximation of the Burgers' equation / the true PDE given by the PINN. <br>\n",
    "\n",
    "```python\n",
    "def f(t,x):\n",
    "    u=u(t,x)\n",
    "    u_t=tf.gradients(u,t)[0]\n",
    "    u_x=tf.gradients(u,x)[0]\n",
    "    u_xx=tf.gradients(u_x,x)[0]\n",
    "    f=u_t+u∗u_x−(0.01/tf.pi)∗u_xx\n",
    "return f\n",
    "```\n",
    "\n",
    "```u(t,x)``` is the approximation given by the PINN of the solution that satisfies the true PDE.\n",
    "\n",
    "```python\n",
    "def u(t,x):\n",
    "    u=neural_net(tf.concat([t,x],1),weights,biases)\n",
    "return u\n",
    "```\n",
    "\n",
    "In other words: ```u(t,x)= NN(t,x) == PINN u``` and ```f(t,x) == NN PDE == PINN PDE``` <br><br>\n",
    "\n",
    "The loss is defined by: $MSE = MSE_f + MSE_u$, it is a combination of the PDE loss $MSE_f$ and the boundary & initial conditions loss $MSE_u$. <br>\n",
    "$MSE_f = \\frac{1}{N_f}\\Sigma_{i=1}^{N_f} |f(t_f^i,x_f^i)|^2$, where $\\{t_f^i,x_f^i\\}_{i=1}^{N_f}$ is the grid generated for the PDE. <br>\n",
    "$MSE_u = \\frac{1}{N_u}\\Sigma_{i=1}^{N_u} |u(t_u^i,x_u^i) - u^i|^2$, where $\\{t_u^i,x_u^i\\}_{i=1}^{N_u}$ is the grid generated for the boundary & initial conditions. <br><br>\n",
    "\n",
    "Architecture used:\n",
    "- 9 layers\n",
    "- 20 neurons\n",
    "- LBFGS optimizer\n",
    "- Weights xavier init\n",
    "- Activation function: tanh\n",
    "- Nu = 100: bc and ic points\n",
    "- Nf = 10000: PDE / collocation points\n",
    "\n",
    "Remark: we want to solve the true PDE without knowing its solution, it can be seen as an unsupervised task where the data required is only the boundary and initial conditions (t = 0, x = -1, 1)).\n",
    "\n",
    "**POURQUOI NF EST PAS SUR LE PLOT, en interne dans le NN?**\n",
    "\n",
    "<div>\n",
    "<img src=\"1.PNG\" width=\"500\"/>\n",
    "</div>\n",
    "<div>\n",
    "<img src=\"2.PNG\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b28ab78",
   "metadata": {},
   "source": [
    "### 3)PINN Approach: Identification => find the PDE (Appendix B1 Data-driven discovery of partial differential equations)\n",
    "\n",
    " you know the solution and you want to discover the parameters in equation F(t, x, u(t, x), \\lambda) = 0. This is a supervised task, where you have a dataset given by the solution defined for every (t, x) \\in \\Omega.\n",
    " \n",
    " Thus, when using the dataset you can use the information coming from IC, BC, and u in the interior of \\Omega."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c080b06e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
